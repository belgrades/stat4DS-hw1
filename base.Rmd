---
title: "HW1"
author: "Gabriel Nespoli | Fernando Crema | Mauricio Fadel Argerich"
date: "October 9, 2016"
output:
 html_document:
    toc: true
    theme: united
---

## Part I: R Syntax & Functions
### a.
The command creates a vector with 4 elements that are characters.
```{r}
vector1 <- c("5", "12", "7", "32")
```
The result of the command will be 7 because it's sorted alphabetically.
```{r}
max(vector1)
```
The vector is sorted alphabetically (not using the numeric value of each element), so the result is: 12, 32, 5, 7.
```{r}
sort(vector1)
```
The command produces an error because it's not possible to sum a vector which elements are characters.
```{r eval=FALSE}
sum(vector1)
```

### b.
The commands don't work. Because the first element of the vector is a character, all the elements in the vector are changed to the most "generic" type of data of its elements which in this case is characters. So when we try to add the second and third element, R tells us it's not possible to add non-numeric arguments, because they're characters.
```{r eval=FALSE}
vector2 <- c("5", 7, 12) 
vector2[2] + vector2[3]
```
The commands work and the result is 19 (7+12). A mainframe can contain different kind of data types, so even the first element is a character, the other elements are number and adding the second and third element works fine.
```{r}
dataframe3 <- data.frame(z1 = "5", z2 = 7, z3 = 12) 
dataframe3[1,2] + dataframe3[1,3]
```
Each element of a list is a list, when we do list4[2] we get the second element of the list (with its name and value), while doing list4[[2]] returns the value of the element. This is why the second command in the code chunk works while the last one doesn't.
```{r eval=FALSE}
list4 <- list(z1 = "6", z2 = 42, z3 = "49", z4 = 126) 
list4[[2]] + list4[[4]]
list4[2] + list4[4]
```

### c.
From 1 to 10000 in increments of 372.
```{r}
seq(from = 1,
    to = 10000,
    by = 372)
```
Sequence of 50 numbers from 1 to 10000.
```{r}
seq(from = 1,
    to = 10000,
    length.out = 50)
```

### d.
This command repeats the whole vector 3 times in order.
```{r}
rep(1:3, 
    times = 3)
```
While this command repeats each element of the vector 3 times (before passing on to the next element).
```{r}
rep(1:3, 
    each = 3)
```

## *Part II:* "Massage" your data.

### a. Reading with `read.delim`
We used the following 4 parameters.

1. **file:** The name of the file you want to read.
1. **header:** Binary parameter. If TRUE then the first _row_ of the file is the header. Conversely, if it's FALSE then the first row of the file isn't a header.
1. **sep:** The character separator in our file. In our case, the character tab ("\t").
1. **stringsAsFactors:** Binary parameter. If TRUE then every string column will be transformed into data type factor, otherwise it'll remain as character.

```{r}
youraw = read.delim(file = "you.tsv",
                    header = TRUE,
                    sep = "\t",
                    stringsAsFactors = FALSE)

str(object = youraw)
```

### b. How many rows and columns does _youraw_ have?

It has 68 rows and 6 columns.
```{r}
# Number of rows
nrow(youraw)

# Number of columns.
ncol(youraw)
``` 

### c. What are the names of the columns of youraw?

The names are: 

1. "Where.are.you.from"
1. "Previous..academic..life"
1. "How.well.do.you.know..Probability"
1. "How.well.do.you.know..Statistics"
1. "How.well.do.you.know..R"                                         
1. "Besides.R..do.you.fluently.know.use.other.programming.languages."

```{r}
names(youraw)
```

### d. What is the value of row 7, column 5 of youraw?

The value is 3.

```{r}
youraw[7, 5]
```

### e. Display the second row of youraw in its entirety.

```{r}
youraw[2, ]
```

### f. Now explain what this command does:

```{r}
youclean <- youraw
names(youclean)
```

We make a copy of the list and called it ```youclean```. Then, we run the command ```names(youclean)``` which changes the name of the columns given the entry array. 

```{r}
names(youclean) <- c("where", "prev.life", "good.prob", "good.stat", "good.R", "other.lan")
names(youclean)
```

### g. Creation of two new variables ```lan1``` and ```lan2```

**The Task:**

The goal is to create two new variables inside the dataset youclean – named ```lan1``` and ```lan2```
– which contains the first two options listed in other.lan. In case less than two options are provided,
fill in the new variables with NA as needed.

**Solution:**

Our approach consist in creating a ```base``` array of programming languages and use string manipulation functions to find matches of all elements in the ```base``` array. Then, we sort the matches and pick the first 2 elements. Finally, if there are less than 2 matches we fill the NA's as needed.

We decided this instead of different approaches for several reasons:

1. The task is to find **programming languages**. As a result, the are 7 cases where the _technology_ described **are not** programming languages. These are:

    * **[Turbo pascal](http://turbopascal.org/):** Is an IDE which has a compiler for the programming language pascal. Therefore, we added pascal as a possible language in ```base```.
    * **[MySQL](http://www.mysql.com/):** Is a relational database management system (RDBMS) which uses SQL that is known to be turing complete, therefore we added sql as the programming language.
    * **[Android](https://www.android.com/):** Is a Mobile Operating System in which you need several languages to develop applications. Therefore, we did not add a programming language with android.
    * **[Windows](https://www.microsoft.com/it-it/):** Is an Operating System that can be related to multiple programming languages. In this case, we did not add a programming language 
    * **[LabView](http://www.ni.com/labview/i/):** Is a System Design Software designed for a graphical programming language called (G). As a result we added G as a possible programming language.
    * **CSS** and **XML**: CSS is a style sheet language used for describing the presentation of a document written in a markup language [Wikipedia/CSS](https://en.wikipedia.org/wiki/Cascading_Style_Sheets) and XML is a markup language that defines a set of rules for encoding documents in a format that is both human-readable and machine-readable [Wikipedia/XML](https://en.wikipedia.org/wiki/XML). By their own, CSS and XML are not programming languages they can be consideredas such if they work together with HTML ([Example of interaction between HTML and CSS](http://eli.fox-epste.in/rule110/)). We decided, however, not to include them in our programming languages array ```base```.
    
1. There is not a clear structure of the answers given by the students. We can find indeed several patterns such as:

    * They usually responded Yes or No at the beginning of the sentence.
    * They usually separated the languages with commas.
    * Sometimes, they added text before or after the programming languages.
    * Everyone wrote ```C++``` which may have problems with regular expressions. Therefore, we changed to ```cpp```. 
    
    
1. In the future, we think that if the number of students increases the chance of getting an unusual pattern is high. Therefore, with our ```base``` array we just need to add a new programming language to the array if we have not seen it before.

    * **Note:** The proper solution should be finding a file with _all_ the programming languages and load it everytime we run our algorithm. We found this [List of Programming Languages](https://en.wikipedia.org/wiki/List_of_programming_languages). We could have made the list but instead we decided just to put the languages used in our scope.
    
1. Finally, even though our solution may be in theory slower than another approaches. We expect student's answers to be short.

```{r}
# Array of languages
languages = c("cpp", "matlab", "bash","js", "javascript","java", "sql", "c", "sas", "python", "objective-c",  "pascal", "ruby", "html", "php", "shell", "assembly", "c#", "pl-sql")

# New columns to youclean
lan1arr = character()
lan2arr = character()

# Preprocessing: Transforming languages to proper syntax.
answers = tolower(youclean$other.lan)
answers = gsub("pl/sql", "pl-sql", answers)
answers = gsub("objective c", "objective-c", answers)
answers = gsub("c\\+\\+", "cpp", answers)
answers = gsub("mysql", "sql", answers)

# Substitution of special characters to whitespace
answers = gsub("\\,", " ", answers)
answers = gsub("\\."," ", answers)
answers = gsub("/"," ", answers)
answers = gsub("!"," ", answers)

for(answer in answers){
  # Assuming minimum positions 99999
  min_1 = 99999
  min_2 = 99999
  
  # Default languages as NA
  lan1 = NA
  lan2 = NA
  
  # Split every answer in whitepaces
  for(chunk in strsplit(answer, " ")[[1]]){
    
    # Trim eliminates whitespaces on the left and right of string.
    chunk = trimws(chunk)
    
    # For every language, we search if exists in every chunk
    for(language in languages){
       
      # Returns the position of the occurrence of the language in the chunk, -1 otherwise 
      position = regexpr(language, chunk, fixed=TRUE)
      
      # If the language exists in the chunk and has the same length as the chunk
       if(position[1]>-1 && nchar(chunk) == nchar(language)){
         
        # In case the position is lower than our minimum, update min_1 and min_2
        if(position[1] < min_1){
          min_2 = min_1
          lan2 = lan1
          
          min_1 = position[1]
          lan1 = language 
          
          # If we find 1 language it's impossible to find another in the chunk.
          break
        }else if(position[1] < min_2){
          min_2 = position[1]
          lan2 = language
          
          # BIS
          break
        }
      }
    }  
  }
  
  # Update arrays.
  lan1arr = c(lan1arr, lan1)
  lan2arr = c(lan2arr, lan2)
}

# Create new columns
youclean$lan1 = lan1arr
youclean$lan2 = lan2arr
```

### h. Very (not) last step: Data Types.

1. Run the following code on your data and explain what it does:

    * **class:**  Used to define or identify what "type" an object is from the point of view of object-oriented programming in R.
    * **typeof:** Determines the (R internal) type or storage mode of any object.
    * **mode:** Get or set the type or storage mode of an object.

    According to the [Manual of R](http://stat.ethz.ch/R-manual/R-devel/doc/manual/R-lang.html#Objects) the main difference between **typeof** and **mode** is that _mode gives information about the mode of an object in the sense of Becker, Chambers & Wilks (1988), and is more compatible with other implementations of the S language_. Conversely, **typeof** gives the type of the object from R internal point of view.

1. Explain the difference you see between the first three and the last three lines of code.

    In the first three lines, the type, class and mode of the column **where** were the same (character). This means that every entry of every row of the column **where** is stored as plain text. In contrast, when we transformed the column with function ```as.factor``` we changed the R class to **factor**, the R internal type of storage to **integer** and the type of the object in the sense of S to **numeric**. 

    This said, the ```as.factor``` function transform the object to a list of interger where every integer is mapped to a list of trings containing the original data. 

```{r}
# Before
class(youclean$where)
typeof(youclean$where)
mode(youclean$where)

# Change to factor
youclean$where <- as.factor(youclean$where)
levels(youclean$where)
nlevels(youclean$where)
```

```{r}
# After
class(youclean$where)
typeof(youclean$where)
mode(youclean$where)
```

Recycle the relevant part of this code to turn into factors also prev.life

```{r}
youclean$prev.life <- as.factor(youclean$prev.life)
```

### i: Saving file
Using ```save``` command to save our data youclean and youraw. 

```{r}
save(youclean, youraw, file="you.RData")
```

# Part III: Exercises from the blue book

## Definitions and properties:

Some definitions and properties will be used on the exercises. Each reference will be used given the number here.

$\text{(1) }\forall E,F \in \Omega \text{ we have } E^{c}\cap F^{c} = \left ( E\cup F \right )^{c} \\ \text{(2) }\forall E,F \in \Omega \text{ we have } E^{c}\cup F^{c} = \left ( E\cap F \right )^{c}  \\ \text{(3) }\forall A \in \Omega \text { we have }\mathbb{P} \left( A^{c} \right) = 1 - \mathbb{P} \left( A \right) \\ \text{(4) } \forall A,B \in \Omega \text{ we have } \mathbb{P}\left ( A\cup B \right )=\mathbb{P}\left ( A \right )+\mathbb{P}\left ( B \right )-\mathbb{P}\left ( A\cap B \right )\\ \text{(5) } \forall A,B \in \Omega \text{ with } \mathbb{P}\left( B \right) > 0 \text{ we have } \mathbb{P}\left(A | B\right) = \displaystyle \frac{\mathbb{P}\left( A \cap B\right)}{\mathbb{P}\left( B \right) }$

## **1. Probability basics – Chapters 2 & 3**

### Problem 2.2

Let $E$ and $F$ be two events for which one knows that the probability that at least one of them occurs is $\frac{3}{4}$. What is the probability that neither E nor F occurs? Hint: use one of DeMorgan’s laws: $E^{c}\cap F^{c} = \left ( E\cup F \right )^{c}$.

#### Solution:
$$\text{We know: } \mathbb{P}\left ( E\cup F \right ) = \frac{3}{4} \text{. So,}$$

$$
\begin{aligned}
  \mathbb{P}\left ( E^{c}\cap F^{c} \right ) = & \mathbb{P}\left ( \left ( E\cup F \right )^{c} \right) && \text{(1)}  \\
  = & 1 - \mathbb{P}\left ( E\cup F \right ) && \text{(3)} \\ 
  = & 1 - \frac{3}{4}  = \frac{1}{4}
\end{aligned}
$$


### Problem 2.6

When $\mathbb{P}\left ( A \right ) = \frac{1}{3}, \mathbb{P}\left ( B \right ) = \frac{1}{2} \text{ and } \mathbb{P}\left ( A \cup B \right ) = \frac{3}{4}$ what is:

a. $\mathbb{P}\left ( A\cap B \right )$?
b. $\mathbb{P}\left ( A^{c}\cup B^{c} \right )$?

#### Solution:

a. 
$$
  \begin{aligned}
    \mathbb{P}\left ( A\cap B \right ) = & \mathbb{P}\left ( A \right ) + \mathbb{P}\left ( B \right ) - \mathbb{P}\left ( A\cup B \right )&& \text{ (4) } \\
    = & \frac{1}{3}+\frac{1}{2}-\frac{3}{4} = \frac{1}{12} \approx 0.083
  \end{aligned}
$$

b.
$$
 \begin{aligned}
  \mathbb{P}\left ( A^{c}\cup B^{c} \right ) 
    = & \mathbb{P}\left ( \left ( A\cap B \right )^{c} \right ) && \text{ (2)} \\
    = &1-\mathbb{P}\left( A\cap B \right ) && \text{ (3)}  \\
    = &1-\frac{1}{12} = \frac{11}{12} \approx  0.917
 \end{aligned}
$$

### Problem 2.9

We toss a coin three times. For this experiment we choose the sample space:

$$\Omega = \left \{HHH, THH, HTH, HHT, TTH, THT, HTT, TTT \right \}$$

where $T$ stands for tails and $H$ for heads.

a. Write down the set of outcomes corresponding to each of the following events:

    $A: ``\text{we throw the tails exactly two times"} \\ B: ``\text{We throw tails at least two times"} \\ C: ``\text{tails did not appear before a head appeared"} \\ D: ``\text{The first result throw results in tails"}$
    
b. Write down the set of outcomes corresponding to each of the following events: $A^{c}$, $A \cup \left(C \cap D \right)$, and $A \cap D^{c}$.

#### Solution

a. $$ $$
    
    $A=\left \{ HTT,THT,TTH \right \} \\ B=\left \{ HTT,THT,TTH,TTT \right \} \\ C=\left \{ HHH,HTT,HTH \right \} \\ D=\left \{ THH,THT,TTT,TTH \right \}$

b. $$ $$
    $\\ \begin{aligned} A^{c}= & \Omega - A \\ = & \left \{HHH, THH, HTH, HHT, TTH, THT, HTT, TTT \right \} - \left \{ HTT,THT,TTH \right \} \\ = & \left \{ HHH,THH,HTH,HHT,TTT \right \} \end{aligned}$
        
    $\begin{aligned}A\cup (C\cap D)= & \left \{ HTT,THT,TTH \right \}\cup \left ( \left \{ HHH,HTT,HTH \right \}\cap \left \{ THH,THT,TTT,TTH \right \} \right ) \\ = &\left \{ HTT,THT,TTH \right \}\cup \emptyset \\ = & \left \{ HTT,THT,TTH \right \} \end{aligned}$
        
    $\begin{aligned} A\cap D^{c}= & \left \{ HTT,THT,TTH \right \}\cap \left \{ HHH,HTT,HTH,HHT \right \} \\ = &\left \{ HTT \right \} \end{aligned}$
    
### Problem 3.5

A ball is drawn at random from an urn containing one red and one white ball. If the white ball is drawn, it is put back into the urn. If the red ball is drawn, it is returned to the urn together with two more red balls. Then a second draw is made. What is the probability a red ball was drawn on both the first and the second draws?

#### Solution

Given the experiment, we have the events:

$\\ R_{1} = \left \{ \text{Draw of red ball in first attempt} \right \} \\ R_{2} = \left \{\text{Draw of red ball in second attempt} \right \}$

We know that: $\mathbb{P}\left ( R_{1} \right ) = \displaystyle \frac{1}{2} \text{ and }\mathbb{P}\left ( R_{2} | R_{1}\right ) = \displaystyle \frac{3}{4}$

We need to calculate: $\mathbb{P}\left ( R_{1} \cap R_{2} \right )$
$$
  \begin{aligned}
    \mathbb{P}\left( R_{1} \cap R_{2} \right) = & \mathbb{P}\left(R_{1}\right) \cdot \mathbb{P}\left(R_{2} \mid R_{1}\right) && \text{ (5)} \\ 
 & = \frac{1}{2} \cdot \frac{3}{4} = \frac{3}{8} = 0.375
  \end{aligned}
$$


### Problem 3.10

A student takes a multiple-choice exam. Suppose for each question he either knows the answer or gambles and chooses an option at random. Further suppose that if he knows the answer, the probability of a correct answer is 1, and if he gambles this probability is $\frac{1}{4}$. To pass, students need to answer at least 60% of the questions correctly. The student has “studied for a minimal pass,” i.e., with probability 0.6 he knows the answer to a question. Given that he answers a question correctly, what is the probability that he actually knows the answer?

#### Solution

We have the events:

$\\C: ``\text{Answering a question correctly"} \\K: ``\text{Knowing the answer to a question""}$

We know that: $\mathbb{P}\left ( K \right ) = 0.6 \rightarrow \mathbb{P}\left ( K^{c} \right ) = 0.4 \text{, } \mathbb{P}\left ( C\mid K \right ) = 1 \text{ and }\mathbb{P}\left ( C\mid K^{c} \right ) = \frac{1}{4}$


We need to calculate: $\mathbb{P}\left ( K\mid C \right )$

$$
  \begin{aligned}
    \mathbb{P}\left ( K\mid C \right ) = & \frac{\mathbb{P}\left ( K \right ) \cdot \mathbb{P}\left ( C\mid K \right )}{\mathbb{P}\left ( C \right )} \\
    = & \frac{\mathbb{P}\left ( K \right ) \cdot \mathbb{P}\left ( C\mid K \right )}{\mathbb{P}\left ( K \right ) \cdot
\mathbb{P}\left ( C\mid K \right ) + \mathbb{P}\left ( K^{c} \right) \cdot \mathbb{P}\left( C\mid K^{c} \right )} \\
= &  \frac{1 \cdot 0.6}{1 \cdot 0.6 + 0.25 \cdot 0.4} = \frac{6}{7} \approx 0.857
  \end{aligned}
$$


### Problem 3.11

A breath analyzer, used by the police to test whether drivers exceed the legal limit set for the blood alcohol percentage while driving, is known to satisfy:

$$ \mathbb{P}\left(A \mid B \right) = \mathbb{P}\left( A^{c} \mid B^{c} \right) = p$$

where $A$ is the event “breath analyzer indicates that legal limit is exceeded” and $B$ “driver’s blood alcohol percentage exceeds legal limit.” On Saturday night about 5% of the drivers are known to exceed the limit.

a. Describe in words the meaning of $\mathbb{P}\left( B^{c} \mid A\right)$.
b. Determine $\mathbb{P}\left( B^{c} \mid A\right)$ if $p=0.95$.
c. How big should $p$ be so that $\mathbb{P} \left( A \mid B\right)=0.9$. 

#### Solution

a. $\mathbb{P}\left ( B^{c}\mid A \right ) =$ "Probability that the blood of the driver doesn't exceed the legal limit given that the breath analyzer indicates it does"

b. We have the events:

    $\\A: ``\text{breath analyzer indicates that legal limit is exceeded"} \\B: ``\text{driver’s blood alcohol percentage exceeds legal limit."}$
    
    We know that: $\mathbb{P}\left(A \mid B \right) = \mathbb{P}\left( A^{c} \mid B^{c} \right) = p \text{ }$ Therefore, $\mathbb{P}\left(A^{c} \mid B \right) = \mathbb{P}\left( A \mid B^{c} \right) = 1-p \text{ using (3)}$
    
    With $p=0.05$ we have $\mathbb{P}\left(A \mid B \right) = \mathbb{P}\left( A^{c} \mid B^{c} \right) = 0.05 \text{ }$ and $\mathbb{P}\left(A^{c} \mid B \right) = \mathbb{P}\left( A \mid B^{c} \right) = 0.95$
    
    Assuming that behaviour on Saturdays remains in the whole week we have that: $\mathbb{P}\left(B\right) = 0.05$ and $\mathbb{P}\left(B^{c}\right) = 0.95$ 
    
    We need to calculate: $\mathbb{P}\left ( B^{c}\mid A \right )$

    $$
    \begin{aligned}
      \mathbb{P}\left ( B^{c}\mid A \right ) = & \frac{\mathbb{P}\left ( A\mid B^{c} \right )\cdot \mathbb{P}\left ( B^{c} \right )}{\mathbb{P}\left ( A \right )}\\
       = & \frac{\mathbb{P}\left ( A\mid B^{c} \right )\cdot \mathbb{P}\left ( B^{c} \right )}{\mathbb{P}\left ( A\mid B \right )\cdot \mathbb{P}\left ( B \right ) + \mathbb{P}\left ( A\mid B^{c} \right )\cdot \mathbb{P}\left ( B^{c} \right )} \\
       = & \frac{\left ( 1 - \mathbb{P}\left ( A^{c}\mid B^{c} \right ) \right )\cdot \left ( 1 - \mathbb{P}\left ( B \right ) \right )}{\mathbb{P}\left ( A\mid B \right )\cdot \mathbb{P}\left ( B \right ) + 
    \left ( 1 - \mathbb{P}\left ( A^{c}\mid B^{c} \right ) \right )\cdot \left ( 1 - \mathbb{P}\left ( B \right ) \right )} \\
     = & \frac{\left ( 1 - 0.95 \right )\cdot \left ( 1 - 0.05 \right )}{0.95\cdot 0.05 + \left ( 1 - 0.95 \right )\cdot \left ( 1 - 0.05 \right )} = 0.5
    \end{aligned}
    $$

c. Assuming same scenario than in b. (but $p=0.95$) we now need to find how big should $p$ be so that $\mathbb{P} \left( B \mid A\right)=0.9$.

    We need $p$ such that $\mathbb{P} \left( B \mid A\right)=0.9$

$$
\begin{aligned}
  \\\mathbb{P}\left ( B\mid A \right ) = & \frac{\mathbb{P}\left ( A\mid B \right )\cdot \mathbb{P}\left ( B \right )}{\mathbb{P}\left ( A \right )}\\
  0.90 = & \frac{\mathbb{P}\left ( A\mid B \right )\cdot \mathbb{P}\left ( B \right )}{\mathbb{P}\left ( A\mid B \right )\cdot \mathbb{P}\left ( B \right ) + \mathbb{P}\left ( A\mid B^{c} \right )\cdot \mathbb{P}\left ( B^{c} \right )} \\ 
 0.90 = & \frac{p\cdot \mathbb{P}\left ( B \right )}{p\cdot \mathbb{P}\left ( B \right ) + \left ( 1 - p \right )\cdot \mathbb{P}\left ( B^{c} \right )}\\
  0.90 = & \frac{p\cdot 0.05}{p\cdot 0.05 + \left ( 1 - p \right )\cdot 0.95}\\
  p\cdot 0.05 = & 0.90 \cdot \left ( p\cdot 0.05 + \left ( 1 - p \right )\cdot 0.95 \right ) & \text{ because } p\cdot 0.05 + \left ( 1 - p \right )\cdot 0.95 >0\\
  0.05 \cdot p = &  0.90 \cdot \left ( -0.90 \cdot p + 0.95 \right )  \\
  0.05 \cdot p = & -0.81 \cdot p + 0.855 \\
  0.05 \cdot p + 0.81 \cdot p = & 0.855\\
  0.86 \cdot p = & 0.855\\
  p = & \frac{0.855}{0.86} = \frac{855}{860} = \frac{171}{172}
\end{aligned}
$$

d. 
    Therefore, $p$ should be $\displaystyle \frac{171}{172}$. Let's check:
        
    $\displaystyle \mathbb{P}\left( B \mid A \right) = \displaystyle \frac{\displaystyle \frac{5 \cdot 171}{100 \cdot 172}}{\displaystyle \frac{5 \cdot 171}{100 \cdot 172}+ \displaystyle\frac{95 \cdot 1}{100 \cdot 172}} = \frac{855}{950} = \frac{9}{10}$


### Problem 3.18
Suppose $A$ and $B$ are events with $0 < \mathbb{P}\left(A\right) < 1$ and $0 < \mathbb{P}\left(B\right) < 1$.

a. If $A$ and $B$ are disjoint, can they be independent?
b. If $A$ and $B$ are independent, can they be disjoint?
c. If $A \subset B$, can $A$ and $B$ be independent?
d. If $A$ and B are independent, can $A$ and $A \cup B$ be independent?

#### Solution
a. Let $A$ and $B$ disjoint events such that $0 < \mathbb{P}\left(A\right) < 1$ and $0 < \mathbb{P}\left(B\right) < 1$. So, 
    let's assume that $A$ and $B$ are independent. $\mathbb{P}\left(A \cap B\right) = \mathbb{P}\left(A\right) \cdot \mathbb{P}\left(B\right)$. 
    Therefore, to be independent it must satisfy $\mathbb{P}\left(A \cap B\right) = \mathbb{P}\left(\emptyset\right) = 0$ because $A \cap B = \emptyset$. 
    Then, $\mathbb{P}\left(A\right) \cdot \mathbb{P}\left(B\right) = 0$. 
    But we know that $\mathbb{P}\left(A\right) > 0$, $\mathbb{P}\left(B\right)>0$ then $\mathbb{P}\left(A\right) \cdot \mathbb{P}\left(B\right)>0$.
    As a result, if $A$ and $B$ are disjoint, $0 < \mathbb{P}\left(A\right) < 1$ and $0 < \mathbb{P}\left(B\right) < 1$ they can't be independent.

b. Let $A$ and $B$ independent events such that $0 < \mathbb{P}\left(A\right) < 1$ and $0 < \mathbb{P}\left(B\right) < 1$. So, if  $A$ and $B$ are independent then $\mathbb{P}\left(A \cap B\right) = \mathbb{P}\left(A\right) \cdot \mathbb{P}\left(B\right)$. We know that $\mathbb{P}\left(A\right) > 0$ and $\mathbb{P}\left(B\right)>0$ then $\mathbb{P}\left(A\right) \cdot \mathbb{P}\left(B\right)>0$. Which means, $A \cap B \neq \emptyset$. Finally, if $A$ and $B$ are independent, $0 < \mathbb{P}\left(A\right) < 1$ and $0 < \mathbb{P}\left(B\right) < 1$ they can't be disjoint.

c. Let $A$ and $B$ events such that $A \subset B$ and $0 < \mathbb{P}\left(A\right) < 1$ and $0 < \mathbb{P}\left(B\right) < 1$. For $A$ and $B$ to be independent it must be satisfied that $\mathbb{P}\left(A \cap B\right) = \mathbb{P}\left(A\right) \cdot \mathbb{P}\left(B\right)$ and we know that if $A \subset B$ then $A \cap B = A$. Therefore using both premises we have $\mathbb{P}\left(A\right) \cdot \mathbb{P}\left(B\right) = \mathbb{P}\left(A\right)$ which means, as $\mathbb{P}\left(A\right) >0$, that $\mathbb{P}\left(B\right)=1$. But, by definition $\mathbb{P}\left(B\right)<1$. Finally, if $A \subset B$, $0 < \mathbb{P}\left(A\right) < 1$ and $0 < \mathbb{P}\left(B\right) < 1$ they can't be independent.

d.  Let $A$ and $B$ independent events such that $0 < \mathbb{P}\left(A\right) < 1$ and $0 < \mathbb{P}\left(B\right) < 1$. So, $\mathbb{P}\left(A \cap \left(A \cup B\right) \right) = \mathbb{P}\left( \left(A \cap A\right) \cup \left(A \cap B\right) \right) = \mathbb{P}\left(A\right) + \mathbb{P}\left(A \cap B\right) - \mathbb{P}\left(A \cap B\right) = \mathbb{P}\left(A\right)$.  Let's assume that $A$ and $A \cup B$ are independent then $\mathbb{P}\left(A \cap\left(A \cup B\right) \right) = \mathbb{P}\left(A\right) \cdot \mathbb{P}\left(A \cup B\right)$. We now have that $\mathbb{P}\left(A\right) \cdot \mathbb{P}\left(A \cup B\right) = \mathbb{P}\left(A\right)$ which means $\mathbb{P}\left(A \cup B\right) = 1$ and $A \cup B =\Omega$ because $\mathbb{P}\left(A\right) > 0$. Now, let's use the probability of a union:

$$
\begin{aligned}
  \mathbb{P}\left(A \cup B\right) = & \mathbb{P}\left(A\right) + \mathbb{P}\left(B\right) - \mathbb{P}\left(A \cap B\right) \\
  1 = & \mathbb{P}\left(A\right) + \mathbb{P}\left(B\right) - \mathbb{P}\left(A \cap B\right) && A \cup B =\Omega \\
  1 = & \mathbb{P}\left(A\right) + \mathbb{P}\left(B\right) - \mathbb{P}\left(A\right) \cdot \mathbb{P}\left(B\right) && A \text{ and } B \text{ independent} \\
  1 - \mathbb{P}\left(A\right) = & \mathbb{P}\left(B\right) - \mathbb{P}\left(A\right) \cdot \mathbb{P}\left(B\right) \\
   1 - \mathbb{P}\left(A\right) = & \mathbb{P}\left(B\right) \cdot \left(1 - \mathbb{P}\left(A\right) \right) && \text{Distributive} \\
   \mathbb{P}\left(A^{c}\right) = &  \mathbb{P}\left(B\right) \cdot \mathbb{P}\left(A^{c}\right) && \text{(3)} \\ 
   1 = & \mathbb{P}\left(B\right) &&  \mathbb{P}\left(A^{c}\right) > 0
\end{aligned}
$$But, by definition $\mathbb{P}\left(B\right)<1$. Therefore, if $A$ and $B$ are independent, $0 < \mathbb{P}\left(A\right) < 1$ and $0 < \mathbb{P}\left(B\right) < 1$ then $A$ and $A \cup B$ can't be independent.

## 2. Topic: Discrete random variables – Chapter 4

### 4.2

### 4.11

The probability of winning one contest is independent to the probability of winning the other. Also, the probability of winning in any month is independent of the previous ones, so M has a geometric distribution with parameters:

$$\\p = p_{1} \cdot p_{2} + p_{1} (1 - p_{2})+ p_{2} (1 - p_{1})$$ 

### 4.14
#### a) 
We can get P(X=2) only if we get one head in the first toss and another head in the second toss. Since the probability of getting a head is p, then:
$$
P(X=2) = p*p = p^2
$$
In addition, to have 2 heads in 3 tossing, it is necessary to get a tail before the second head. We have to possibilities (HTH,THH). So,
$$
P(X=3) = p(1-p)p + (1-p)p^2 = 2(1-p)p^2
$$
In the same way, to get 2 heads in 4 tossing, we need  to have 2 tails before the second head: (HTTH,TTHH,THTH). Which gives us:
$$
P(X=4) = p(1-p)(1-p)p + (1-p)(1-p)p^2 + (1-p)p(1-p)p = 3(1-p)^2p^2
$$

#### b) 
It is easy to think that in order to get two heads, by any path of the tree of possibilities, we will have a $p^2$ associated in the equation of P(X=n). Furthermore, we will have always (1-n) possible paths to have X=n. Lastly, to have 2 heads in n, firstly we nead to have (n-2) tails before the second head. Of course, getting two heads can only occurs if $n\geq2$. According to this, we have:

$$
P(X=n)=(n-1) p^2 (1-p)^{n-2}, n\geq2
$$

# Part IV: Coins, Randomness and Genetics
##Summary of the video:
The video starts talking about how many times do we need to shuffle the deck of cards to make it random, which means, the cards before the shuffle are totally different just after. As we know, the smaller the deck, the easier is tho get it shuffled randomly, because if the deck is 4 cards, them the number of possibilities is 4! = 4x3x2 = 24.

But usually we cannot try out all the possibilities. In a complete deck of 52 cards, it means that we have 52! possibilities of sequences of cards, which results in more than $8x10^{67}$ possibilities.

Also, the mentioned that if you give an ordered deck of cards to a friend and tell him to shuffle by  the common way of shuffling (without seeing while he does), which divides the deck in two parts of almost the same size, and  shuffle them and put them together again, you will still have $2^{number\_of\_shuffles}$ rising 'small' sequences in the middle of the deck. If your friend mix 3 times, so there's 8 rising sequences in the deck. And then you do a magic: remove cards one by one. If a card is not in order with the previous card, you start another pile. If it's in order, you put in the same pile. In the 9th pile is the card that the person has taken.

He affirmed again, practically, the deck is never completely mixed, it is not random. He raised a question: how much do we accept it to be shuffled? It will not be random, but how much do we consider it enough?

When he cites the on-line poker, he  compares that to have a deck really shuffled randomly, you would need to have computer with the capacity to process numbers in the order of  $6x10^{67}$, which is far from the possibilities of a computer of 32 bits ($2^{32} = 4,3$ billions possibilities).

Then, a student asked how about to put the cards on the table and mash them with the hands. He explained that this is efficient and is hard to predict the result or the efficiency of this method because it is hard to model this method, but certainly, with 8x10^67 possibilities, there will be still cards in sequence.

Another student suggested to take off the top ten cards, and shuffle and then shuffle the rest of the deck. The professor explained that there is many machines in Vegas which use this idea: the deck enters in the machine and cards are separated in ten shelves, some on and others under the pile. But again, the problem resides that the decision that the machine does is based in the random number which it generates, again $2^{32}$ or $2^{64}$.

He explained again that practically nothing is random because we do not try all the possibilities: we do not shuffle the cards enough, we do not toss the coin enough, etc.

He stated that the problem of lack of randomness in tossing coins is because we use Physics, we can define the position in which the coin will end. If we know the initial condition (head or tail), apply a known force in a known region of the coin, you can know the height that the coin will reach and how many turns it will spin, so you can tell how it will end - tail or head.

So, he concludes that nothing is completely random.

# **Part V:** A naive version of the Naive Bayes Classifier
The exercise gives us a table of the historical events of four weather parameters (outlook, temperature, humidity, wind) and, based in these weather conditions, we played tennis or not. Then, knowing the weather condition for today, it asks us if we will play tennis. In other words, based in our past experience with the given condition, i.e. Outlook = Sunny, Temperature = Cool, Humidity = High , Wind = Strong, what is most propable evidence expected?

We start to compute the total "Yes" and "No" probability. In overall table, how many times we played tennis and how many we did not:
```{r eval=FALSE}
P(Play = Yes) = 9/14
P(Play = No) = 5/14
```

Considering this results, we calculate how many times we played tennis and how many we didn't for each hypothesis. For example, the conditional probability of playing tennis in a sunny day is:

```{r eval=FALSE}
P(Outlook = Sunny | Play = Yes) = 2/9
P(Outlook = Sunny | Play = No) = 3/5
```

For the others hypothesis, we have:

Outlook
```{r eval=FALSE}
P(Outlook = Overcast | Play = Yes) = 4/9
P(Outlook = Overcast | Play = No) = 0/5
P(Outlook = Rain | Play = Yes) = 3/9
P(Outlook = Rain | Play = No) = 2/5
```

Temperature
```{r eval=FALSE}
P(Temperature = Hot | Play = Yes) = 2/9
P(Temperature = Hot | Play = No) = 2/5
P(Temperature = Mild | Play = Yes) = 4/9
P(Temperature = Mild | Play = No) = 2/5
P(Temperature = Cool | Play = Yes) = 3/9
P(Temperature = Cool | Play = No) = 1/5
```

Humidity
```{r eval=FALSE}
P(Humidity = High | Play = Yes) = 3/9
P(Humidity = High | Play = No) = 4/5
P(Humidity = Normal | Play = Yes) = 6/9
P(Humidity = Normal | Play = No) = 1/5
```

Wind
```{r eval=FALSE}
P(Wind = Strong | Play = Yes) = 3/9
P(Wind = Strong | Play = No) = 3/5
P(Wind = Weak | Play = Yes) = 6/9
P(Wind = Weak | Play = No) = 2/5
```

Considering these evidences hypothesis, to evaluate the probability of playing tennis or not, we have to calculate the expressions:

```{r eval=FALSE}
argmax{P(Yes | Outlook = Sunny, Temperature = Cool, Humidity = High , Wind = Strong),
P(No | Outlook = Sunny, Temperature = Cool, Humidity = High , Wind = Strong)}
```

Calculating each argument separetely we have:
```{r eval=FALSE}
P(Yes | (Sunny, Cool, High , Strong)) = P(Yes)*[P(Sunny|Yes)*P(Cool|Yes)*P(High|Yes)*P(Strong|Yes)]
```
And
```{r eval=FALSE}
P(No | (Sunny, Cool, High , Strong)) = P(No)*[P(Sunny|No)*P(Cool|No)*P(High|No)*P(Strong|No)]
```

Which gives us:
```{r eval=FALSE}
P(Yes | (Sunny, Cool, High , Strong)) = (9/14)*(2/9 * 3/9 * 3/9 * 3/9)
P(No | (Sunny, Cool, High , Strong)) = (5/14)*(3/5 * 1/5 * 4/5 * 3/5)
```

Naming P(Yes | (Sunny, Cool, High , Strong)) P_Yes and P(No | (Sunny, Cool, High , Strong)) P_No and calculating, we have:

```{r}
P_Yes <- (9/14)*(2/9 * 3/9 * 3/9 * 3/9)
P_Yes

P_No <- (5/14)*(3/5 * 1/5 * 4/5 * 3/5)
P_No
```

As P_No is greater than P_Yes, we will not play tennis tomorrow.
